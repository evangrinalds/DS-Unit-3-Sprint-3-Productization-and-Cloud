{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "DS-Unit-3-Sprint-3-Sprint-Challenge.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "26331cfec4792162c2f8fe9b562702d2",
          "grade": false,
          "grade_id": "cell-f2b2468124042cfe",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "5fyquvOrzzkG"
      },
      "source": [
        "_Lambda School Data Science, Unit 2_\n",
        "\n",
        "---\n",
        "\n",
        "ðŸ‘‡ **Do not change the code in this cell.** If you're working in Google Colab, you can run this cell to install `category_encoders` and `pdpbox`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "6e84593629f1e735cc6423e463199480",
          "grade": false,
          "grade_id": "cell-656c869f2d287493",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "8vvVzINUzzkH"
      },
      "source": [
        "%%capture\n",
        "import sys\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "    !pip install category_encoders\n",
        "    !pip install pdpbox"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "be6f7489d8b09d515eed676f06ac2d3b",
          "grade": false,
          "grade_id": "cell-dbdc2fe26ba31738",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "HmDBGH3lzzkI"
      },
      "source": [
        "# Sprint Challenge: Predict Chicago Food Inspections ðŸ•\n",
        "\n",
        "In this challenge, you'll use data from the [Chicago Department of Public Health](https://www.chicago.gov/city/en/depts/cdph/provdrs/healthy_restaurants/svcs/food-protection-services.html) to build a model to predict whether a food establishment passed inspection or not.\n",
        "\n",
        "The purpose of this model is to help inspectors use their time more efficiently by identifying establishments that will likely fail inspection. In other words, this model should be able to predict whether an establishment will fail inspection *before* the inspector arrives at the establishment. \n",
        "\n",
        "# Directions\n",
        "\n",
        "This notebook contains 12 tasks, which cover the material we've learned in this sprint. Here's a summary:\n",
        "\n",
        "- **Task 1:** Importing data.\n",
        "- **Task 2:** Identifying data leakage.\n",
        "- **Task 3:** Writing a wrangle function.\n",
        "- **Task 4:** Splitting data into a feature matrix and target vector.\n",
        "- **Task 5:** Splitting data into training and validation sets.\n",
        "- **Task 6:** Establishing baseline accuracy.\n",
        "- **Task 7:** Building model with bagging predictor.\n",
        "- **Task 8:** Building model with boosting predictor.\n",
        "- **Task 9 (`stretch goal`):** Plotting ROC curves.\n",
        "- **Task 10:** Generating classification report.\n",
        "- **Task 11:** Calculating permutation importances.\n",
        "- **Task 12 (`stretch goal`):** Creating PDP interaction plot.\n",
        "\n",
        "For each task you should do the following:\n",
        "\n",
        "- Read the task instructions.\n",
        "- Write your code in the cell below the task. Delete the `raise NotImplementedError` before your start.\n",
        "- Run the testing cell below the task. If you get an error, read the error message and re-evaluate your code.\n",
        "\n",
        "**You should limit your code to the following libraries:**\n",
        "\n",
        "- `category_encoders`\n",
        "- `numpy`\n",
        "- `matplotlib`\n",
        "- `pandas`\n",
        "- `pdpbox`\n",
        "- `sklearn`\n",
        "- `xgboost`\n",
        "\n",
        "**A word of warning:** The virtual machine that will check your answers is small. So, where applicable, don't use huge values for `n_estimators` (`>100`) or `n_jobs` (keep at `-1`). \n",
        "\n",
        "If you'd like to import all your libraries at the start of your notebook, you can do so in the code block below ðŸ‘‡"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "313c53b0dc59a11bb7bfaefbf995fe2c",
          "grade": false,
          "grade_id": "cell-44be413734e30691",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "dajLG--uzzkI"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, roc_curve, plot_confusion_matrix, plot_roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "from category_encoders import OrdinalEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.inspection import permutation_importance\n",
        "from pdpbox.pdp import pdp_isolate, pdp_plot, pdp_interact, pdp_interact_plot\n",
        "#raise NotImplementedError()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "48dd82293df0d9af1aa7efac7f7468fa",
          "grade": false,
          "grade_id": "cell-602d346d44303e87",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "koJcNmltzzkI"
      },
      "source": [
        "# I. Wrangle Data\n",
        "\n",
        "**Task 1:** Change the code below to import your dataset. Be sure to examine the columns carefully and determine if one of them should be set as the index."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "dafd956974169191567e3544c18186a5",
          "grade": false,
          "grade_id": "cell-8b9246d8d97a80ff",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "twyf9tMKzzkJ",
        "outputId": "9f3b0d1c-d136-4db8-b73a-3040ebcb8b68"
      },
      "source": [
        "'''T1. Import data file.'''\n",
        "url = 'https://drive.google.com/uc?export=download&id=1aUnQ4AJK4UtW8JL9zPyYUMtkjIgQpqKT'\n",
        "df = pd.read_csv(url, parse_dates=['Inspection Date'], index_col='Inspection Date')\n",
        "# YOUR CODE HERE\n",
        "df.head()\n",
        "#raise NotImplementedError()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Inspection ID</th>\n",
              "      <th>DBA Name</th>\n",
              "      <th>AKA Name</th>\n",
              "      <th>License #</th>\n",
              "      <th>Facility Type</th>\n",
              "      <th>Risk</th>\n",
              "      <th>Address</th>\n",
              "      <th>City</th>\n",
              "      <th>State</th>\n",
              "      <th>Zip</th>\n",
              "      <th>Inspection Type</th>\n",
              "      <th>Violations</th>\n",
              "      <th>Latitude</th>\n",
              "      <th>Longitude</th>\n",
              "      <th>Location</th>\n",
              "      <th>Fail</th>\n",
              "      <th>Serious Violations Found</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Inspection Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2017-09-15</th>\n",
              "      <td>2088270</td>\n",
              "      <td>TOM YUM RICE &amp; NOODLE, INC.</td>\n",
              "      <td>TOM YUM CAFE</td>\n",
              "      <td>2354911.0</td>\n",
              "      <td>Restaurant</td>\n",
              "      <td>Risk 1 (High)</td>\n",
              "      <td>608 W BARRY</td>\n",
              "      <td>CHICAGO</td>\n",
              "      <td>IL</td>\n",
              "      <td>60657.0</td>\n",
              "      <td>Canvass</td>\n",
              "      <td>3. POTENTIALLY HAZARDOUS FOOD MEETS TEMPERATUR...</td>\n",
              "      <td>41.938007</td>\n",
              "      <td>-87.644755</td>\n",
              "      <td>{'longitude': '-87.6447545707008', 'latitude':...</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-10-20</th>\n",
              "      <td>555268</td>\n",
              "      <td>FILLING STATION  &amp; CONVENIENCE  STORE</td>\n",
              "      <td>FILLING STATION  &amp; CONVENIENCE  STORE</td>\n",
              "      <td>1044901.0</td>\n",
              "      <td>Grocery Store</td>\n",
              "      <td>Risk 3 (Low)</td>\n",
              "      <td>6646-6658 S WESTERN AVE</td>\n",
              "      <td>CHICAGO</td>\n",
              "      <td>IL</td>\n",
              "      <td>60636.0</td>\n",
              "      <td>Complaint Re-Inspection</td>\n",
              "      <td>32. FOOD AND NON-FOOD CONTACT SURFACES PROPERL...</td>\n",
              "      <td>41.772402</td>\n",
              "      <td>-87.683603</td>\n",
              "      <td>{'longitude': '-87.68360273081268', 'latitude'...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-04-05</th>\n",
              "      <td>1751394</td>\n",
              "      <td>A P DELI</td>\n",
              "      <td>A P DELI</td>\n",
              "      <td>47405.0</td>\n",
              "      <td>Restaurant</td>\n",
              "      <td>Risk 1 (High)</td>\n",
              "      <td>2025 E 75TH ST</td>\n",
              "      <td>CHICAGO</td>\n",
              "      <td>IL</td>\n",
              "      <td>60649.0</td>\n",
              "      <td>Canvass Re-Inspection</td>\n",
              "      <td>35. WALLS, CEILINGS, ATTACHED EQUIPMENT CONSTR...</td>\n",
              "      <td>41.758779</td>\n",
              "      <td>-87.575054</td>\n",
              "      <td>{'longitude': '-87.57505446746121', 'latitude'...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-04-29</th>\n",
              "      <td>1763905</td>\n",
              "      <td>FRANK'S CHICAGO SHRIMP HOUSE</td>\n",
              "      <td>FRANK'S CHICAGO SHRIMP HOUSE</td>\n",
              "      <td>6414.0</td>\n",
              "      <td>Restaurant</td>\n",
              "      <td>Risk 2 (Medium)</td>\n",
              "      <td>4459 S ARCHER AVE</td>\n",
              "      <td>CHICAGO</td>\n",
              "      <td>IL</td>\n",
              "      <td>60632.0</td>\n",
              "      <td>Canvass</td>\n",
              "      <td>38. VENTILATION: ROOMS AND EQUIPMENT VENTED AS...</td>\n",
              "      <td>41.812181</td>\n",
              "      <td>-87.707125</td>\n",
              "      <td>{'longitude': '-87.70712481334274', 'latitude'...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-10</th>\n",
              "      <td>453326</td>\n",
              "      <td>MORRILL</td>\n",
              "      <td>MORRILL</td>\n",
              "      <td>24571.0</td>\n",
              "      <td>School</td>\n",
              "      <td>Risk 1 (High)</td>\n",
              "      <td>6011 S Rockwell (2600W) AVE</td>\n",
              "      <td>CHICAGO</td>\n",
              "      <td>IL</td>\n",
              "      <td>60629.0</td>\n",
              "      <td>Canvass</td>\n",
              "      <td>34. FLOORS: CONSTRUCTED PER CODE, CLEANED, GOO...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Inspection ID  ... Serious Violations Found\n",
              "Inspection Date                 ...                         \n",
              "2017-09-15             2088270  ...                      2.0\n",
              "2011-10-20              555268  ...                      0.0\n",
              "2016-04-05             1751394  ...                      0.0\n",
              "2016-04-29             1763905  ...                      0.0\n",
              "2011-01-10              453326  ...                      0.0\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "493ede874f1e2c163a74021a41d8775d",
          "grade": false,
          "grade_id": "cell-1b2eb047117d89ab",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "r_fXHIQ8zzkJ"
      },
      "source": [
        "**Task 1 Test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "0d68298cfa23877cd61b8ba487c19dc6",
          "grade": true,
          "grade_id": "cell-e9593d4f4ed7a9bb",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "S8Orzo-DzzkJ"
      },
      "source": [
        "'''T1 Test'''\n",
        "assert isinstance(df, pd.DataFrame), 'Have you created a DataFrame named `df`?'\n",
        "assert len(df) == 51916"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "1ee62609b3bf18520406b3837f7843a6",
          "grade": false,
          "grade_id": "cell-9e90dce33ddd0506",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "stoUh0yEzzkJ"
      },
      "source": [
        "**Task 2:** Given that this model is supposed to generate predictions *before* an inspection is conducted, identify the numerical feature that is an example of **data leakage.** Assign the column name to the variable `'leaky_col'`.\n",
        "\n",
        "**Remember:** Leakage is when your feature matrix includes columns that will not be available to your model at the time it make predictions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "27b878765c52a092c3c56791dde91d5d",
          "grade": false,
          "grade_id": "cell-ef24afc9168ad64f",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "9bw47Iz-zzkJ"
      },
      "source": [
        "'''T2. Identify data leakage column.'''\n",
        "leaky_col = 'Serious Violations Found'\n",
        "# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "9874ad6b513dd2c2e409aa1d6610a65e",
          "grade": false,
          "grade_id": "cell-378fd448d54e6fc0",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "NBtIftLizzkJ"
      },
      "source": [
        "**Task 2 Test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "5a57c6a47e502a421524daf29beb7941",
          "grade": true,
          "grade_id": "cell-8429f30efb2a7bf7",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "0sTm_SM8zzkJ"
      },
      "source": [
        "'''T2 Test'''\n",
        "# This is a hidden test. \n",
        "# You'll see the result when you submit to Canvas.\n",
        "assert isinstance(leaky_col, str), '`leaky_col` should be type `str`.'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "b17eb5d6c465729f58b1739a11ea5b96",
          "grade": false,
          "grade_id": "cell-2f7298cea62c493e",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "QdrghT66zzkK"
      },
      "source": [
        "**Task 3:** Add to the `wrangle` function below so that it does the following:\n",
        "\n",
        "- Removes the \"leaky\" column.\n",
        "- Removes high-cardinality categorical columns (more than `500` categories).\n",
        "- Removes categorical columns that have only one category.\n",
        "- Removes numerical columns that are unique identifiers for each observation, not features that would affect the target."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "40e1745bb407a170e1dec8221d37fc3c",
          "grade": false,
          "grade_id": "cell-d6fc5ee398afff4f",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "Nv64Hwg2zzkK"
      },
      "source": [
        "'''T3. Write wrangle function.'''\n",
        "def wrangle(df):\n",
        "  df.drop(columns= ['State', 'Inspection ID', 'License #', leaky_col], inplace=True)\n",
        "  categorical_cols = df.select_dtypes('object').columns\n",
        "  threshold = 500\n",
        "  high_card_cols = [col for col in categorical_cols if df[col].nunique() > threshold]\n",
        "  df.drop(high_card_cols, axis = 1, inplace= True)\n",
        "  return df\n",
        "# YOUR CODE HERE\n",
        "df = wrangle(df)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "22afb4a381b73f41b02f83ca4a0102bd",
          "grade": false,
          "grade_id": "cell-7b5d539f39db8415",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "oO2P9wjzzzkK"
      },
      "source": [
        "**Task 3 Test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "05d5f964ad8d8bf468bd907abaa85213",
          "grade": true,
          "grade_id": "cell-49f495efb58bcd9f",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "DRmQKNdAzzkK"
      },
      "source": [
        "'''T3 Test'''\n",
        "assert df.select_dtypes('object').nunique().max() < 500, 'Have you dropped the high-cardinality columns?'\n",
        "assert df.select_dtypes('object').nunique().min() > 1, 'Have you dropped the column with only one category?'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "f93a157b989f3327402d7b93a31bb595",
          "grade": false,
          "grade_id": "cell-aea953fa5337fc1f",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "hippEpVOzzkK"
      },
      "source": [
        "# II. Split Data\n",
        "\n",
        "**Task 4:** Split the DataFrame `df` into the feature matrix `X` and the target vector `y`. Your target is `'Fail'`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "7bfd4151db9dd6615a624da2954138e8",
          "grade": false,
          "grade_id": "cell-b21b1c40f5478337",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "cS2JgwfMzzkK"
      },
      "source": [
        "'''T4. Split feature matrix and target vector.'''\n",
        "target = 'Fail'\n",
        "# YOUR CODE HERE\n",
        "y = df[target]\n",
        "X = df.drop(target, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "2f00ae85d10438328017da8b01b77354",
          "grade": false,
          "grade_id": "cell-d9a64e5a6bd2a37d",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "xj-csbySzzkK"
      },
      "source": [
        "**Task 4 Test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "04db76e9023f0b61187af1e39513d377",
          "grade": true,
          "grade_id": "cell-a1d912e28c9f7522",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "ShEfdBdszzkL"
      },
      "source": [
        "'''T4 Test'''\n",
        "assert y.shape == (51916,), '`y` either has the wrong number of rows, or is two-dimentional.'\n",
        "assert len(X) == 51916, '`X` has the wrong number of rows.'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "e719471298c6c418489a657a500b7d0e",
          "grade": false,
          "grade_id": "cell-b575fbda93b87f6a",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "gzJ2h1CLzzkL"
      },
      "source": [
        "**Task 5:** Split your dataset into training and validation sets.\n",
        "\n",
        "- Your training set (`X_train`, `y_train`) should contain inspections conducted before 2017.\n",
        "- Your validation set (`X_val`, `y_val`) should contain inspections conducted during or after 2017."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f92b2b9f9460a17c987c23188e3c31b1",
          "grade": false,
          "grade_id": "cell-0bb47689fd4667ed",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "XLGehTKZzzkL"
      },
      "source": [
        "'''T5. Split dataset into training and validation sets.'''\n",
        "# YOUR CODE HERE\n",
        "train_mask = df.index.year < 2017\n",
        "X_train, y_train = X.loc[train_mask], y.loc[train_mask]\n",
        "val_mask = df.index.year >= 2017\n",
        "X_val, y_val = X.loc[val_mask], y.loc[val_mask]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "60e77b85e7db0d0cb2522b8caa399e77",
          "grade": false,
          "grade_id": "cell-8517b2d477256843",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "GQwxhLpuzzkL"
      },
      "source": [
        "**Task 5 Testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "56e9e6ef918d3a662decf3f6d67dfd01",
          "grade": true,
          "grade_id": "cell-52cf3ef1934a4278",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "eko6H4k4zzkL"
      },
      "source": [
        "'''T5 Test'''\n",
        "assert len(X_train) == len(y_train) == 41827, 'Your training set has the wrong number of observations.'\n",
        "assert len(X_val) == len(y_val) == 10089, 'Your validation set has the wrong number of observations.'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "0641d242faca29af591ebea98bc88ed6",
          "grade": false,
          "grade_id": "cell-2e9a4c74f50ed0fc",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "VXDWnx-hzzkL"
      },
      "source": [
        "# III. Establish Baseline\n",
        "\n",
        "**Task 6:** Establish the baseline accuracy score for this classification problem using your training set. Save the score to the variable `baseline_acc`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "b658c6901efe4fe564387be697265352",
          "grade": false,
          "grade_id": "cell-3d21cc97649be107",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "QFGBAjcIzzkL"
      },
      "source": [
        "'''T6. Establish baseline accuracy.'''\n",
        "# YOUR CODE HERE\n",
        "baseline_acc = y_train.value_counts(normalize=True).max()\n",
        "print('Baseline accuracy:', baseline_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "6098c9452685d029c07b96f5295b5c1d",
          "grade": false,
          "grade_id": "cell-56d5801c8831c15b",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "HBuy8RgozzkL"
      },
      "source": [
        "**Task 6 Testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "8527a8f2e79c09d69519059e56c54272",
          "grade": true,
          "grade_id": "cell-abdc4cbe95e9d1da",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "70FQjyeCzzkL"
      },
      "source": [
        "'''T6 Test'''\n",
        "assert isinstance(baseline_acc, float), '`baseline_acc` should be type float. Have you defined the variable?'\n",
        "assert 0.0 <= baseline_acc <= 1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "8a0f7eab56c05e92a441333652ccf6cf",
          "grade": false,
          "grade_id": "cell-7d68939c4eced62c",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "jQ0soA0NzzkL"
      },
      "source": [
        "# IV. Build Model\n",
        "\n",
        "In this section, you want to answer the question: Which ensemble method performs better with this data â€” bagging or boosting?\n",
        "\n",
        "**Task 7:** Build a model that includes a bagging predictor (`RandomForest`). Your predictor should be part of a pipeline named `model_bag` that includes any transformers that you think are necessary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "49a48b340c0ee7f9630c3ce57e4ca439",
          "grade": false,
          "grade_id": "cell-889285d53fdbe282",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "jnmm1LGvzzkL"
      },
      "source": [
        "'''T7. Build model with bagging predictor.'''\n",
        "# YOUR CODE HERE\n",
        "model_bag = make_pipeline(\n",
        "    OrdinalEncoder(),\n",
        "    SimpleImputer(),\n",
        "    RandomForestClassifier(random_state=42, max_depth=12)\n",
        ")\n",
        "model_bag.fit(X_train, y_train);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "81055fe5d87448fd8e4aff2ca4f10ea0",
          "grade": false,
          "grade_id": "cell-72dac6ede9a13038",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "fr3Ehm7szzkM"
      },
      "source": [
        "**Tast 7 Testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "57725e1ca8a837d8fa761271f994ad44",
          "grade": true,
          "grade_id": "cell-cddc5d7d2170877b",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "2kf5-SlKzzkM"
      },
      "source": [
        "'''T7 Testing'''\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "assert isinstance(model_bag, Pipeline), '`model_bag` is the wrong data type. Have you assigned your pipeline to the correct variable name?'\n",
        "assert isinstance(model_bag[-1], RandomForestClassifier), 'Your predictor should be a `RandomForestClassifier`.'\n",
        "assert hasattr(model_bag[-1], 'feature_importances_'), 'Have you trained your model?'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "5e3c031075213c671f8f9b321585e9eb",
          "grade": false,
          "grade_id": "cell-d9750931390fe58f",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "Nh3r5FKfzzkM"
      },
      "source": [
        "**Task 8:** Build a model that includes a boosting predictor (`GradientBoostingClassifier` from `sklearn` or `XGBClassifier` from `xgboost`). Your predictor should be part of a pipeline named `model_boost` that includes any transformers that you think are necessary. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a30d11fa6b0d4e143f4572b0baf65afb",
          "grade": false,
          "grade_id": "cell-37f16b5811ae5223",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "Vw0G2AjSzzkM"
      },
      "source": [
        "'''T8. Build model with boosting predictor.'''\n",
        "# YOUR CODE HERE\n",
        "model_boost = make_pipeline(\n",
        "    OrdinalEncoder(),\n",
        "    SimpleImputer(),\n",
        "    GradientBoostingClassifier(random_state=42)\n",
        ")\n",
        "model_boost.fit(X_train, y_train);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "64d1c2ff5004fe02082dc204299e0e70",
          "grade": false,
          "grade_id": "cell-3699731f62fa5db3",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "1nYAfwAtzzkM"
      },
      "source": [
        "**Task 8 Testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "35744289b60d1556e064bc09da544566",
          "grade": true,
          "grade_id": "cell-90deb42a1c052402",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "So08LGtdzzkM"
      },
      "source": [
        "'''T8 Testing'''\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "assert isinstance(model_boost, Pipeline), '`model_boost` is the wrong data type. Have you assigned your pipeline to the correct variable name?'\n",
        "assert any([isinstance(model_boost[-1], XGBClassifier),\n",
        "            isinstance(model_boost[-1], GradientBoostingClassifier)]), 'Your predictor should be `XGBClassifier` or `GradientBoostingClassifier`.'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "ebed19854d947c07608d2cb6c356f7ec",
          "grade": false,
          "grade_id": "cell-dc041ac00c805cff",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "8khTSXZszzkM"
      },
      "source": [
        "# V. Check Metrics\n",
        "\n",
        "Here are the accuracy scores for your two models. Did you beat the baseline? Which of your two models appears to perform better on your validation set?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "fc12491c98afa1dd0767422ce0a07b22",
          "grade": false,
          "grade_id": "cell-c0206a761fccab6c",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "T17r-tpFzzkM"
      },
      "source": [
        "print('Bagging Model')\n",
        "print('Training accuracy:', model_bag.score(X_train, y_train))\n",
        "print('Validation accuracy:', model_bag.score(X_val, y_val))\n",
        "print()\n",
        "print('Boosting Model')\n",
        "print('Training accuracy:', model_boost.score(X_train, y_train))\n",
        "print('Validation accuracy:', model_boost.score(X_val, y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "044f92b1e1321a290f39d2a3d4f756ed",
          "grade": false,
          "grade_id": "cell-17e8e5433e896bc5",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "zMM8qc91zzkM"
      },
      "source": [
        "**Task 9 (`stretch_goal`):** Plot the ROC-curve for both of your models (you can plot them one-at-a-time, side-by-side, or in the same plot)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "e4a418ccf53481f58016cf1828e973da",
          "grade": false,
          "grade_id": "cell-769e4a780bb22283",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "CXrhjwzwzzkM"
      },
      "source": [
        "'''T9. Plot ROC-curve.'''\n",
        "# YOUR CODE HERE\n",
        "Boost = plot_roc_curve(model_boost, X_val, y_val)\n",
        "Bag = plot_roc_curve(model_bag,\n",
        "                   X_val,\n",
        "                   y_val,\n",
        "                   ax=Boost.ax_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "c2a7559346e95bf6ecd31e90dcefd3be",
          "grade": false,
          "grade_id": "cell-1b8571c3a6a034f5",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "g_JO0dLxzzkM"
      },
      "source": [
        "**Task 10:** Choose one of your models based on your validation accuracy score or your ROC curves. Then create a classification report for that model using your validation data. Save the text of the report to the variable name `model_cr`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "2ef340cbc8ec53da648b929c0bab96ef",
          "grade": false,
          "grade_id": "cell-49891c4ce9bf5f37",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "UEBMzvjLzzkM"
      },
      "source": [
        "'''T10. Generate classification report for one model.'''\n",
        "from sklearn.metrics import classification_report\n",
        "# YOUR CODE HERE\n",
        "model_cr = classification_report(y_val, model_bag.predict(X_val))\n",
        "print(model_cr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "103296abc9f51aa4b883c35c418275cc",
          "grade": false,
          "grade_id": "cell-7b5374efd0e40c69",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "a8Zq3zEKzzkM"
      },
      "source": [
        "**Task 10 Testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "110853de9aaaba37cb2fe601091b1e7d",
          "grade": true,
          "grade_id": "cell-94e04c938f3f5f84",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "ZDnI8fYdzzkN"
      },
      "source": [
        "assert isinstance(model_cr, str), '`model_cr` should be type `str`.'\n",
        "assert all(term in model_cr for term in ['precision', 'recall', 'f1-score', 'support']), 'Is this a classification report?'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "00449a4317e9b4d383f2ca7d58a2b0af",
          "grade": false,
          "grade_id": "cell-d2b4843352d3085a",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "66nPcMbmzzkN"
      },
      "source": [
        "**Task 11:** Using your best model, create a DataFrame `permutation_importances` with the model's permutation importances based on your validation data.\n",
        "\n",
        "- The index of the DataFrame should be your feature names.\n",
        "- The first column should be the mean importance.\n",
        "- The second column should be the importance standard deviation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f8e984b2a5083b74b7eb0abec46f8d63",
          "grade": false,
          "grade_id": "cell-72936eec6980072b",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "6ozugglWzzkN"
      },
      "source": [
        "'''T11. Create DataFrame of permutation importances.'''\n",
        "# YOUR CODE HERE\n",
        "perm_importances = permutation_importance(model_bag, \n",
        "                                  X_val, \n",
        "                                  y_val, \n",
        "                                  n_repeats=5, \n",
        "                                  n_jobs=-1, \n",
        "                                  random_state=42)\n",
        "data = {'mean': perm_importances['importances_mean'],\n",
        "        'std': perm_importances['importances_std']}\n",
        "permutation_importances = pd.DataFrame(data, index=X_val.columns).sort_values(by='mean')\n",
        "permutation_importances.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "dccb1015d0f5c2f8b23f780eb8e4abf7",
          "grade": false,
          "grade_id": "cell-9eb949d189e401bc",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "d-HTADpCzzkN"
      },
      "source": [
        "**Task 11 Testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "d84e55cd6e77a52c576972ab68477c90",
          "grade": true,
          "grade_id": "cell-a4d8990e7070c2dd",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "QL9Miip2zzkN"
      },
      "source": [
        "'''Task 11 Test'''\n",
        "assert isinstance(permutation_importances, pd.DataFrame), '`permutation_importances` should be type `DataFrame`.'\n",
        "assert permutation_importances.shape == (7,2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "f005618a5eb29cde9fbc73ab717b0e1c",
          "grade": false,
          "grade_id": "cell-3d8938c1715a596d",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "jSyF4VmtzzkN"
      },
      "source": [
        "**Task 12 (`stretch goal`):** Using your best model, create a PDP interaction plot to examine how `'Latitude'` and `'Longitude'` inform predictions. Remember to user your validation data.\n",
        "\n",
        "**Note:** Because of the way that `pdp_interact` works, it will throw an error if there are `NaN` values in your validation set. To avoid this problem, be sure to set `dataset` to `X_val.dropna()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ea5a8422d2efafe17ee63a77c5db1e41",
          "grade": false,
          "grade_id": "cell-224d3b408f9bdd88",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "SVFbtxz2zzkN"
      },
      "source": [
        "'''T12. Create PDP interaction plot for \"Latitude\" and \"Longitude\".'''\n",
        "features = ['Longitude', 'Latitude']\n",
        "# YOUR CODE HERE\n",
        "isolate = pdp_interact(\n",
        "    model_bag,\n",
        "    dataset = X_val.dropna(),\n",
        "    model_features = X_val.columns,\n",
        "    features = features\n",
        ")\n",
        "pdp_interact_plot(isolate, plot_type='grid', feature_names= features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "ea11277dc1543cb3a51dc7cf050af8a9",
          "grade": false,
          "grade_id": "cell-60908df556f5057e",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "0ipFz6cazzkN"
      },
      "source": [
        "What do you think? Is there a relationship between location and failing a food saftey inspection?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-EVUa158mdE"
      },
      "source": [
        "#### Based off the pdp interaction plot, there is a relationship between location and failing a food safety inspection."
      ]
    }
  ]
}